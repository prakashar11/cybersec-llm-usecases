# Cybersecurity Use cases that Utilize Large Language Models (LLM)

## 1. Threat Modeling
- AI-powered threat modeling tool that leverages OpenAI's GPT models [https://github.com/mrwadams/stride-gpt]
- GitHub action for generating threat modeling recommendation [https://github.com/xvnpw/ai-threat-modeling-action]
## 2. LLM Guardrails
- A lightweight library to sanitize data provided to AI tools [https://github.com/Deploying-Securely/GPT-Guard]
- Adding programmable guardrails to LLM-based conversational systems [https://github.com/NVIDIA/NeMo-Guardrails/]
- Reference implementation to identify string similarities between potential banned prompts and the prompts sent by the clients [https://github.com/protectai/rebuff/blob/main/server/lib/detect-helpers.ts]
## 3. AI Firewall/Proxy
- Security and compliance proxy for LLM APIs [https://github.com/usagepanda/proxy]
- Prompt injection detector [https://github.com/protectai/rebuff/tree/main]
## 4. Vulnerability Scanner
- Probe for hallucination, data leakage, prompt injection, misinformation, toxicity generation, jailbreaks, and many other weaknesses [https://github.com/leondz/garak]
- Prompt engineering evaluation and testing toolkit [https://github.com/preset-io/promptimize]
- Test prompt injection risk [https://github.com/utkusen/promptmap]
## 5. Pentest 
- A GPT-empowered penetration testing tool [https://github.com/GreyDGL/PentestGPT]
## 6. Incident Response
- Incident response response based on attack group aligned with MITRE ATT&CK [https://github.com/mrwadams/attackgen]
## 7. Threat Hunting
- Different LLM based threat hunting example Notebooks [https://github.com/OTRF/GenAI-Security-Adventures]
- MITRE assistant by utilizing RAG on the ATT&CK data [https://jupyter.securitybreak.io/RAG_ATT%26CK/RAG_ATT%26CK.html]
- Use MSTICpy package as threat hunting LLM agent [https://blog.securitybreak.io/applying-llms-to-threat-intelligence-f3b8ba4463a4]
